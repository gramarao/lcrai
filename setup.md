# RAG Chat System with Feedback Enhancement

A production-ready Retrieval-Augmented Generation (RAG) system using Google Gemini, PostgreSQL with pgvector, and Streamlit.

## Features

- ðŸ¤– **Multi-Model Support**: Compare different Gemini models (2.5-flash, 2.5-pro, etc.)
- ðŸ“Š **Feedback-Enhanced Retrieval**: Learn from user feedback to improve responses
- ðŸ“ˆ **Quality Analytics**: Track response quality and system performance
- ðŸ”¬ **Model Comparison**: Side-by-side testing of different models
- ðŸ“„ **Document Management**: Upload, manage, and search across documents

## Architecture

- **Backend**: FastAPI with PostgreSQL + pgvector
- **Frontend**: Streamlit multipage app
- **AI**: Google Gemini API with LangChain
- **Database**: PostgreSQL with pgvector extension

## Prerequisites

- Python 3.10+
- PostgreSQL 14+ with pgvector extension
- Google Gemini API key

## Installation

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd rag-chat-system

2. **Create virtual environment**
    ```bash 
    python -m venv lcrai_venv
    source lcrai_venv/bin/activate  # On Windows: lcrai_venv\Scripts\activate

3. **Install dependencies**
    ```bash
    pip install -r requirements.txt

4. Set up PostgreSQL
    ```bash
    # Install pgvector extension
    psql -U postgres -d your_database -c "CREATE EXTENSION vector;"

5. ***Configure Environment variables***
    ```bash
    cp .env.example .env

6. ***Run DB migration***
    ```bash
    python scripts/migrations/migrate_db.py

7. ***Example .env***
    ```bash
    # Database
    DATABASE_URL=postgresql://user:password@localhost:5432/rag_db

    # Google Gemini API
    GOOGLE_API_KEY=your_gemini_api_key_here

    # Model Configuration
    CHAT_MODEL=gemini-2.5-flash
    EMBED_MODEL=models/text-embedding-004
    RETRIEVE_K=5

    # Backend URL
    BACKEND_URL=http://localhost:8000